# Method of Moments 

## Method of Moments
* Procedure for finding an estimator for population parameters.

> Benefit: Simple procedure and yields constent estimators (under weak assumption) and are often unbiased.

## Procedure
1. Set $\mu_{k}^{\prime} \stackrel{\text{set}}{=} m_{k}^{\prime}$ for each parameter to be estimated

    Recall:
    $$\mu\_{k}^{\prime} = E(Y^{k}) \quad m\_{k}^{\prime} =\frac{1}{n}\sum\limits_{i=1}^{n} Y^{k}\_{i}$$

    > $\mu^{\prime}_{k} =$  population moment

    > $m^{\prime}_{k} =$ sample moment average
2. Solve for each parameter of interest

> Always use a lower moment if possible and if a moment pair does not work use the next higher moment

## Example
A random sample of $n$ oberservations, $Y_{1}, Y_{2},..., Y_{n}$ is selected from a population in which $Y_{i}, i \in [1,n]$ possess a unfiorm probability density function over the interval $(0,\theta)$ where $\theta$ is unknown. Use the method of moments to estimate the paramter $\theta$.

$$
\mu^{\prime}\_{1}=E[Y^{1}]=\frac{\theta}{2} \\
m^{\prime}\_{1}=\frac{1}{n}\sum\limits_{i=1}^{n}Y\_{i}=\overline{Y}
$$

## Plug-in Property

If the paramter of interest $\psi$ is a function of another paramter $\theta$ whose MME is relative easy to find $(\psi = g(\theta) )$ and $\hat{\theta}\_{MME}$ is easy to obtain, then we can apply the function $h$ to $\hat{\theta}\_{MME}$ to obtain $\hat{\psi}\_{MME}$
$$\psi=h(\theta)\Rightarrow\hat{\psi}\_{MME}=h(\hat{\theta}\_{MME})$$

## MME and Consistency
* Under some reularity conditions, MME are consistent.

We have $m_{k} \xrightarrow{p} \mu_{k} \quad k = 1, ..., K$

The solution to the equations $\mu_{k} = g(\theta)$
## Additional Readings

https://en.wikipedia.org/wiki/Method_of_moments_(statistics)